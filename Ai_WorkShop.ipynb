{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cakethehacker/Ai_email_filter/blob/main/Ai_WorkShop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htyqeckebza5"
      },
      "source": [
        "# **AI-Powered Content Classification and Sentiment Analysis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOWzXqPqb53k"
      },
      "source": [
        "This notebook presents a step-by-step guide to building an efficient Email spam classification model using the email Spam Collection dataset. By the end of this notebook, you'll have a powerful tool to help you filter out unwanted email messages and ensure that your email messaging experience is smoother and safer. ðŸ™‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWJ4d_WjI6ph"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from google.colab import files\n",
        "import re\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P6tqSVAJOmC"
      },
      "outputs": [],
      "source": [
        "# Upload dataset\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(next(iter(uploaded)), encoding='latin-1')  # or 'cp1252', 'iso-8859-1', etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sSS23o9JQhf"
      },
      "outputs": [],
      "source": [
        "# Display basic dataset info\n",
        "print(df.info())\n",
        "print(df.head())\n",
        "df.describe()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucXj3YzdoEF9"
      },
      "outputs": [],
      "source": [
        "# Text Preprocessing\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "df.dropna(inplace=True)  # Drop missing values\n",
        "df['text'] = df['title'] + ' ' + df['text']  # Combine title and text\n",
        "df['text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGACVoSpoBCp"
      },
      "outputs": [],
      "source": [
        "# Convert labels to numerical values\n",
        "df['label'] = df['type'].apply(lambda x: 1 if x == 'spam' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdITADEAe2TS"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Spam vs. Not Spam Distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=df['label'])\n",
        "plt.title('Spam vs Not Spam Distribution')\n",
        "plt.xlabel('Label (0 = Not Spam, 1 = Spam)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m54Sb7X6sfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkn7f4vxm19X"
      },
      "outputs": [],
      "source": [
        "# Convert text to numerical features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = vectorizer.transform(X_test).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle Class Imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "J-5Xe2ci9xCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCca9cDhd95E"
      },
      "outputs": [],
      "source": [
        "# Get most common words for spam and real emails\n",
        "spam_words = ' '.join(spam_emails).split()\n",
        "real_words = ' '.join(real_emails).split()\n",
        "\n",
        "spam_common = [word for word, count in Counter(spam_words).most_common(20)]\n",
        "real_common = [word for word, count in Counter(real_words).most_common(20)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYig2cu8rrep"
      },
      "outputs": [],
      "source": [
        "# Build Improved Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train_tfidf.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fTEdF9iJbnX"
      },
      "outputs": [],
      "source": [
        "# Train model and save each epoch's model\n",
        "best_val_accuracy = 0.0\n",
        "best_model_path = \"best_epoch_model.h5\"\n",
        "\n",
        "for epoch in range(1, 41):\n",
        "    history = model.fit(X_train_tfidf, y_train, epochs=1, batch_size=32, validation_data=(X_test_tfidf, y_test), verbose=1)\n",
        "    model_path = f\"epoch_model_{epoch}.h5\"\n",
        "    model.save(model_path)\n",
        "    print(f\"Saved {model_path}\")\n",
        "\n",
        "    val_accuracy = history.history['val_accuracy'][0]\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        model.save(best_model_path)\n",
        "        print(f\"Best model updated: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyC6rGgopYoc"
      },
      "outputs": [],
      "source": [
        "_pred_probs = model.predict(X_test_tfidf)\n",
        "y_pred = (y_pred_probs > 0.5).astype('int32')  # Lower threshold to capture more spam\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Training History\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "04sOs3qPsPqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Training History\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "39Iyrk4tqAmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3wXdg_jMroKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_probs)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PCjdwkCq-C4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6vTGqwpV-FXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_csv():\n",
        "    print(\"Upload a CSV file with 'title' and 'text' columns for prediction.\")\n",
        "    uploaded_file = files.upload()\n",
        "    test_df = pd.read_csv(next(iter(uploaded_file)), encoding='latin-1') # Change encoding to 'latin-1' or 'cp1252'\n",
        "\n",
        "    # Convert 'title' and 'text' columns to string type before combining\n",
        "    # Removed the .str causing the error, it is not necessary when columns are already strings\n",
        "    test_df['title'] = test_df['title'].astype(str)\n",
        "    test_df['text'] = test_df['text'].astype(str)\n",
        "\n",
        "    test_df['text'] = test_df['title'] + ' ' + test_df['text']  # Combine title and text\n",
        "    test_tfidf = vectorizer.transform(test_df['text']).toarray()\n",
        "    predictions = (model.predict(test_tfidf) > 0.5).astype('int32')\n",
        "\n",
        "    test_df['prediction'] = predictions\n",
        "    test_df['prediction'] = test_df['prediction'].apply(lambda x: 'Spam' if x == 1 else 'Not Spam')\n",
        "\n",
        "    test_df[test_df['prediction'] == 'Not Spam'].to_csv('primary_mail.csv', index=False, encoding='utf-8')\n",
        "    test_df[test_df['prediction'] == 'Spam'].to_csv('junk_mail.csv', index=False, encoding='utf-8')\n",
        "\n",
        "    print(\"Prediction results saved to 'primary_mail.csv' and 'junk_mail.csv'.\")\n",
        "    print(test_df[['title', 'text', 'prediction']])\n",
        "    return test_df"
      ],
      "metadata": {
        "id": "fNhlzyDqZyrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run prediction on uploaded CSV\n",
        "predicted_df = predict_from_csv()\n"
      ],
      "metadata": {
        "id": "iBm1Z6UVxoiB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}